{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ef80b7-1370-4f0a-a4e3-5a2b5407f80e",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "782c046c-36a5-479b-bb57-960ad7136b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 1333\n",
      "Shape of the TF-IDF matrix: (1333, 17101)\n",
      "Classification Report (Rounded to 3 decimal places):\n",
      "\n",
      "Label: A\n",
      "  precision: 0.8\n",
      "  recall: 0.571\n",
      "  f1-score: 0.667\n",
      "  support: 21.0\n",
      "\n",
      "Label: B\n",
      "  precision: 0.82\n",
      "  recall: 0.891\n",
      "  f1-score: 0.854\n",
      "  support: 46.0\n",
      "\n",
      "Label: C\n",
      "  precision: 0.877\n",
      "  recall: 0.781\n",
      "  f1-score: 0.826\n",
      "  support: 73.0\n",
      "\n",
      "Label: D\n",
      "  precision: 0.8\n",
      "  recall: 0.8\n",
      "  f1-score: 0.8\n",
      "  support: 85.0\n",
      "\n",
      "Label: E\n",
      "  precision: 0.469\n",
      "  recall: 0.19\n",
      "  f1-score: 0.27\n",
      "  support: 79.0\n",
      "\n",
      "Label: F\n",
      "  precision: 0.562\n",
      "  recall: 0.896\n",
      "  f1-score: 0.691\n",
      "  support: 96.0\n",
      "\n",
      "Label: macro avg\n",
      "  precision: 0.721\n",
      "  recall: 0.688\n",
      "  f1-score: 0.685\n",
      "  support: 400.0\n",
      "\n",
      "Label: weighted avg\n",
      "  precision: 0.694\n",
      "  recall: 0.698\n",
      "  f1-score: 0.673\n",
      "  support: 400.0\n",
      "Predicted Category for the new document: F\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "folder_1 = r\"C:\\Users\\86178\\Desktop\\TF-IDF基线模型评估语料\\1\"\n",
    "folder_2 = r\"C:\\Users\\86178\\Desktop\\TF-IDF基线模型评估语料\\2\"\n",
    "\n",
    "\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    labels = []\n",
    "    for txt_file in glob.glob(os.path.join(folder_path, \"*.txt\")):\n",
    "        with open(txt_file, 'r', encoding='utf-8') as file:\n",
    "          \n",
    "            content = file.read().strip().replace('\\n', ' ')  \n",
    "            documents.append(content)\n",
    "           \n",
    "            label = os.path.basename(txt_file)[0]  \n",
    "            labels.append(label)\n",
    "    return documents, labels\n",
    "\n",
    "\n",
    "docs_1, labels_1 = load_documents_from_folder(folder_1)\n",
    "docs_2, labels_2 = load_documents_from_folder(folder_2)\n",
    "\n",
    "\n",
    "documents = docs_1 + docs_2\n",
    "labels = labels_1 + labels_2\n",
    "\n",
    "\n",
    "print(f\"Total number of documents: {len(documents)}\")  \n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "\n",
    "print(f\"Shape of the TF-IDF matrix: {X.shape}\")  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy':\n",
    "        for metric, value in metrics.items():\n",
    "            if isinstance(value, float):\n",
    "                metrics[metric] = round(value, 3)\n",
    "\n",
    "\n",
    "print(\"Classification Report (Rounded to 3 decimal places):\")\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy':\n",
    "        print(f\"\\nLabel: {label}\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value}\")\n",
    "    \n",
    "\n",
    "new_document = [\"Python is great for data science\"]  \n",
    "X_new = vectorizer.transform(new_document)\n",
    "new_pred = svm_classifier.predict(X_new)\n",
    "print(\"Predicted Category for the new document:\", new_pred[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d55cdf-f6ab-4479-a94d-e8e2c619e3d2",
   "metadata": {},
   "source": [
    "# NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c6e9d3a-ce3f-48cd-9842-d68c20da6e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 1333\n",
      "Shape of the TF-IDF matrix: (1333, 17101)\n",
      "Classification Report (Rounded to 3 decimal places):\n",
      "\n",
      "Label: A\n",
      "  precision: 0.0\n",
      "  recall: 0.0\n",
      "  f1-score: 0.0\n",
      "  support: 21.0\n",
      "\n",
      "Label: B\n",
      "  precision: 0.667\n",
      "  recall: 0.217\n",
      "  f1-score: 0.328\n",
      "  support: 46.0\n",
      "\n",
      "Label: C\n",
      "  precision: 0.537\n",
      "  recall: 0.699\n",
      "  f1-score: 0.607\n",
      "  support: 73.0\n",
      "\n",
      "Label: D\n",
      "  precision: 0.586\n",
      "  recall: 0.918\n",
      "  f1-score: 0.716\n",
      "  support: 85.0\n",
      "\n",
      "Label: E\n",
      "  precision: 0.571\n",
      "  recall: 0.051\n",
      "  f1-score: 0.093\n",
      "  support: 79.0\n",
      "\n",
      "Label: F\n",
      "  precision: 0.56\n",
      "  recall: 0.875\n",
      "  f1-score: 0.683\n",
      "  support: 96.0\n",
      "\n",
      "Label: macro avg\n",
      "  precision: 0.487\n",
      "  recall: 0.46\n",
      "  f1-score: 0.404\n",
      "  support: 400.0\n",
      "\n",
      "Label: weighted avg\n",
      "  precision: 0.547\n",
      "  recall: 0.568\n",
      "  f1-score: 0.483\n",
      "  support: 400.0\n",
      "Predicted Category for the new document: F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "folder_1 = r\"C:\\Users\\86178\\Desktop\\TF-IDF基线模型评估语料\\1\"\n",
    "folder_2 = r\"C:\\Users\\86178\\Desktop\\TF-IDF基线模型评估语料\\2\"\n",
    "\n",
    "\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    labels = []\n",
    "    for txt_file in glob.glob(os.path.join(folder_path, \"*.txt\")):\n",
    "        with open(txt_file, 'r', encoding='utf-8') as file:\n",
    "           \n",
    "            content = file.read().strip().replace('\\n', ' ')  \n",
    "            documents.append(content)\n",
    "            \n",
    "            label = os.path.basename(txt_file)[0]  \n",
    "            labels.append(label)\n",
    "    return documents, labels\n",
    "\n",
    "\n",
    "docs_1, labels_1 = load_documents_from_folder(folder_1)\n",
    "docs_2, labels_2 = load_documents_from_folder(folder_2)\n",
    "\n",
    "\n",
    "documents = docs_1 + docs_2\n",
    "labels = labels_1 + labels_2\n",
    "\n",
    "\n",
    "print(f\"Total number of documents: {len(documents)}\") \n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "\n",
    "print(f\"Shape of the TF-IDF matrix: {X.shape}\") \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy':  \n",
    "        for metric, value in metrics.items():\n",
    "            if isinstance(value, float):\n",
    "                metrics[metric] = round(value, 3)\n",
    "\n",
    "\n",
    "print(\"Classification Report (Rounded to 3 decimal places):\")\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy':\n",
    "        print(f\"\\nLabel: {label}\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value}\")\n",
    "\n",
    "\n",
    "new_document = [\"Python is great for data science\"] \n",
    "X_new = vectorizer.transform(new_document)\n",
    "new_pred = nb_classifier.predict(X_new)\n",
    "print(\"Predicted Category for the new document:\", new_pred[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17694fbe-8af6-436b-b0e7-938957f3769e",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcc6d8dd-ba50-45a4-9f02-564e93d0d628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 1333\n",
      "Shape of the TF-IDF matrix: (1333, 17101)\n",
      "Classification Report (Rounded to 3 decimal places):\n",
      "\n",
      "Label: A\n",
      "  precision: 0.293\n",
      "  recall: 0.81\n",
      "  f1-score: 0.43\n",
      "  support: 21.0\n",
      "\n",
      "Label: B\n",
      "  precision: 0.369\n",
      "  recall: 0.522\n",
      "  f1-score: 0.432\n",
      "  support: 46.0\n",
      "\n",
      "Label: C\n",
      "  precision: 0.514\n",
      "  recall: 0.521\n",
      "  f1-score: 0.517\n",
      "  support: 73.0\n",
      "\n",
      "Label: D\n",
      "  precision: 0.455\n",
      "  recall: 0.647\n",
      "  f1-score: 0.534\n",
      "  support: 85.0\n",
      "\n",
      "Label: E\n",
      "  precision: 0.293\n",
      "  recall: 0.152\n",
      "  f1-score: 0.2\n",
      "  support: 79.0\n",
      "\n",
      "Label: F\n",
      "  precision: 0.659\n",
      "  recall: 0.281\n",
      "  f1-score: 0.394\n",
      "  support: 96.0\n",
      "\n",
      "Label: macro avg\n",
      "  precision: 0.43\n",
      "  recall: 0.489\n",
      "  f1-score: 0.418\n",
      "  support: 400.0\n",
      "\n",
      "Label: weighted avg\n",
      "  precision: 0.464\n",
      "  recall: 0.432\n",
      "  f1-score: 0.414\n",
      "  support: 400.0\n",
      "Predicted Category for the new document: F\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "folder_1 = r\"C:\\Users\\86178\\Desktop\\TF-IDF基线模型评估语料\\1\"\n",
    "folder_2 = r\"C:\\Users\\86178\\Desktop\\TF-IDF基线模型评估语料\\2\"\n",
    "\n",
    "\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    labels = []\n",
    "    for txt_file in glob.glob(os.path.join(folder_path, \"*.txt\")):\n",
    "        with open(txt_file, 'r', encoding='utf-8') as file:\n",
    "         \n",
    "            content = file.read().strip().replace('\\n', ' ')  \n",
    "            documents.append(content)\n",
    "           \n",
    "            label = os.path.basename(txt_file)[0]  \n",
    "            labels.append(label)\n",
    "    return documents, labels\n",
    "\n",
    "\n",
    "docs_1, labels_1 = load_documents_from_folder(folder_1)\n",
    "docs_2, labels_2 = load_documents_from_folder(folder_2)\n",
    "\n",
    "\n",
    "documents = docs_1 + docs_2\n",
    "labels = labels_1 + labels_2\n",
    "\n",
    "\n",
    "print(f\"Total number of documents: {len(documents)}\")  \n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "\n",
    "print(f\"Shape of the TF-IDF matrix: {X.shape}\")  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy': \n",
    "        for metric, value in metrics.items():\n",
    "            if isinstance(value, float):\n",
    "                metrics[metric] = round(value, 3)\n",
    "\n",
    "\n",
    "print(\"Classification Report (Rounded to 3 decimal places):\")\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy':\n",
    "        print(f\"\\nLabel: {label}\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value}\")\n",
    "\n",
    "\n",
    "new_document = [\"Python is great for data science\"] \n",
    "X_new = vectorizer.transform(new_document)\n",
    "new_pred = knn_classifier.predict(X_new)\n",
    "print(\"Predicted Category for the new document:\", new_pred[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385eea5a-f6df-423a-b803-e2cf072e6823",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb31a47d-b2eb-4a39-9e4b-87735881a5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 1333\n",
      "Shape of the TF-IDF matrix: (1333, 17101)\n",
      "Classification Report (Rounded to 3 decimal places):\n",
      "\n",
      "Label: A\n",
      "  precision: 1.0\n",
      "  recall: 0.333\n",
      "  f1-score: 0.5\n",
      "  support: 21.0\n",
      "\n",
      "Label: B\n",
      "  precision: 0.861\n",
      "  recall: 0.674\n",
      "  f1-score: 0.756\n",
      "  support: 46.0\n",
      "\n",
      "Label: C\n",
      "  precision: 0.794\n",
      "  recall: 0.74\n",
      "  f1-score: 0.766\n",
      "  support: 73.0\n",
      "\n",
      "Label: D\n",
      "  precision: 0.79\n",
      "  recall: 0.753\n",
      "  f1-score: 0.771\n",
      "  support: 85.0\n",
      "\n",
      "Label: E\n",
      "  precision: 0.5\n",
      "  recall: 0.089\n",
      "  f1-score: 0.151\n",
      "  support: 79.0\n",
      "\n",
      "Label: F\n",
      "  precision: 0.474\n",
      "  recall: 0.958\n",
      "  f1-score: 0.634\n",
      "  support: 96.0\n",
      "\n",
      "Label: macro avg\n",
      "  precision: 0.737\n",
      "  recall: 0.591\n",
      "  f1-score: 0.596\n",
      "  support: 400.0\n",
      "\n",
      "Label: weighted avg\n",
      "  precision: 0.677\n",
      "  recall: 0.637\n",
      "  f1-score: 0.599\n",
      "  support: 400.0\n",
      "Predicted Category for the new document: F\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "folder_1 = r\"C:\\Users\\86178\\Desktop\\TF-IDF基线模型评估语料\\1\"\n",
    "folder_2 = r\"C:\\Users\\86178\\Desktop\\TF-IDF基线模型评估语料\\2\"\n",
    "\n",
    "\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    labels = []\n",
    "    for txt_file in glob.glob(os.path.join(folder_path, \"*.txt\")):\n",
    "        with open(txt_file, 'r', encoding='utf-8') as file:\n",
    "            \n",
    "            content = file.read().strip().replace('\\n', ' ') \n",
    "            documents.append(content)\n",
    "            \n",
    "            label = os.path.basename(txt_file)[0]  \n",
    "            labels.append(label)\n",
    "    return documents, labels\n",
    "\n",
    "\n",
    "docs_1, labels_1 = load_documents_from_folder(folder_1)\n",
    "docs_2, labels_2 = load_documents_from_folder(folder_2)\n",
    "\n",
    "\n",
    "documents = docs_1 + docs_2\n",
    "labels = labels_1 + labels_2\n",
    "\n",
    "\n",
    "print(f\"Total number of documents: {len(documents)}\") \n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "\n",
    "print(f\"Shape of the TF-IDF matrix: {X.shape}\")  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "log_reg_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "\n",
    "log_reg_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy':  \n",
    "        for metric, value in metrics.items():\n",
    "            if isinstance(value, float):\n",
    "                metrics[metric] = round(value, 3)\n",
    "\n",
    "\n",
    "print(\"Classification Report (Rounded to 3 decimal places):\")\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy':\n",
    "        print(f\"\\nLabel: {label}\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value}\")\n",
    "\n",
    "\n",
    "new_document = [\"Python is great for data science\"]  \n",
    "X_new = vectorizer.transform(new_document)\n",
    "new_pred = log_reg_classifier.predict(X_new)\n",
    "print(\"Predicted Category for the new document:\", new_pred[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8afc71b-9d52-4933-81ee-e1f3e7fe8efa",
   "metadata": {},
   "source": [
    "# CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8cf7cc3-9c7b-4863-a4e7-c56ea0dba20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 1333\n",
      "Shape of the TF-IDF matrix: (1333, 17101)\n",
      "Classification Report (Rounded to 3 decimal places):\n",
      "\n",
      "Label: A\n",
      "  precision: 0.3\n",
      "  recall: 0.286\n",
      "  f1-score: 0.293\n",
      "  support: 21.0\n",
      "\n",
      "Label: B\n",
      "  precision: 0.524\n",
      "  recall: 0.478\n",
      "  f1-score: 0.5\n",
      "  support: 46.0\n",
      "\n",
      "Label: C\n",
      "  precision: 0.444\n",
      "  recall: 0.329\n",
      "  f1-score: 0.378\n",
      "  support: 73.0\n",
      "\n",
      "Label: D\n",
      "  precision: 0.486\n",
      "  recall: 0.6\n",
      "  f1-score: 0.537\n",
      "  support: 85.0\n",
      "\n",
      "Label: E\n",
      "  precision: 0.508\n",
      "  recall: 0.418\n",
      "  f1-score: 0.458\n",
      "  support: 79.0\n",
      "\n",
      "Label: F\n",
      "  precision: 0.526\n",
      "  recall: 0.625\n",
      "  f1-score: 0.571\n",
      "  support: 96.0\n",
      "\n",
      "Label: macro avg\n",
      "  precision: 0.465\n",
      "  recall: 0.456\n",
      "  f1-score: 0.456\n",
      "  support: 400.0\n",
      "\n",
      "Label: weighted avg\n",
      "  precision: 0.487\n",
      "  recall: 0.49\n",
      "  f1-score: 0.484\n",
      "  support: 400.0\n",
      "Predicted Category for the new document: F\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "folder_1 = r\"C:\\Users\\86178\\Desktop\\TF-IDF基线模型评估语料\\1\"\n",
    "folder_2 = r\"C:\\Users\\86178\\Desktop\\TF-IDF基线模型评估语料\\2\"\n",
    "\n",
    "\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    labels = []\n",
    "    for txt_file in glob.glob(os.path.join(folder_path, \"*.txt\")):\n",
    "        with open(txt_file, 'r', encoding='utf-8') as file:\n",
    "            \n",
    "            content = file.read().strip().replace('\\n', ' ')  \n",
    "            documents.append(content)\n",
    "           \n",
    "            label = os.path.basename(txt_file)[0] \n",
    "            labels.append(label)\n",
    "    return documents, labels\n",
    "\n",
    "\n",
    "docs_1, labels_1 = load_documents_from_folder(folder_1)\n",
    "docs_2, labels_2 = load_documents_from_folder(folder_2)\n",
    "\n",
    "\n",
    "documents = docs_1 + docs_2\n",
    "labels = labels_1 + labels_2\n",
    "\n",
    "\n",
    "print(f\"Total number of documents: {len(documents)}\")  \n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "\n",
    "print(f\"Shape of the TF-IDF matrix: {X.shape}\") \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = decision_tree_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy':  \n",
    "        for metric, value in metrics.items():\n",
    "            if isinstance(value, float):\n",
    "                metrics[metric] = round(value, 3)\n",
    "\n",
    "\n",
    "print(\"Classification Report (Rounded to 3 decimal places):\")\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy':\n",
    "        print(f\"\\nLabel: {label}\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value}\")\n",
    "\n",
    "\n",
    "new_document = [\"Python is great for data science\"]  \n",
    "X_new = vectorizer.transform(new_document)\n",
    "new_pred = decision_tree_classifier.predict(X_new)\n",
    "print(\"Predicted Category for the new document:\", new_pred[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b6c00-90b1-4843-9788-1d53dc43c4e6",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "940b0d21-f647-4fc9-94dd-814a18b64047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Rounded to 3 decimal places):\n",
      "\n",
      "Label: 0\n",
      "  precision: 0.288\n",
      "  recall: 0.81\n",
      "  f1-score: 0.425\n",
      "  support: 21.0\n",
      "\n",
      "Label: 1\n",
      "  precision: 0.542\n",
      "  recall: 0.696\n",
      "  f1-score: 0.61\n",
      "  support: 46.0\n",
      "\n",
      "Label: 2\n",
      "  precision: 0.72\n",
      "  recall: 0.493\n",
      "  f1-score: 0.585\n",
      "  support: 73.0\n",
      "\n",
      "Label: 3\n",
      "  precision: 0.733\n",
      "  recall: 0.776\n",
      "  f1-score: 0.754\n",
      "  support: 85.0\n",
      "\n",
      "Label: 4\n",
      "  precision: 0.75\n",
      "  recall: 0.19\n",
      "  f1-score: 0.303\n",
      "  support: 79.0\n",
      "\n",
      "Label: 5\n",
      "  precision: 0.566\n",
      "  recall: 0.719\n",
      "  f1-score: 0.633\n",
      "  support: 96.0\n",
      "\n",
      "Label: macro avg\n",
      "  precision: 0.6\n",
      "  recall: 0.614\n",
      "  f1-score: 0.552\n",
      "  support: 400.0\n",
      "\n",
      "Label: weighted avg\n",
      "  precision: 0.649\n",
      "  recall: 0.588\n",
      "  f1-score: 0.571\n",
      "  support: 400.0\n",
      "Predicted Category for the new document: A\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "folder_1 = r\"C:\\Users\\86178\\Desktop\\TF-IDF基线模型评估语料\\1\"\n",
    "folder_2 = r\"C:\\Users\\86178\\Desktop\\TF-IDF基线模型评估语料\\2\"\n",
    "\n",
    "\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    labels = []\n",
    "    for txt_file in glob.glob(os.path.join(folder_path, \"*.txt\")):\n",
    "        with open(txt_file, 'r', encoding='utf-8') as file:\n",
    "         \n",
    "            content = file.read().strip().replace('\\n', ' ')  \n",
    "            documents.append(content)\n",
    "           \n",
    "            label = os.path.basename(txt_file)[0] \n",
    "            labels.append(label)\n",
    "    return documents, labels\n",
    "\n",
    "\n",
    "docs_1, labels_1 = load_documents_from_folder(folder_1)\n",
    "docs_2, labels_2 = load_documents_from_folder(folder_2)\n",
    "\n",
    "\n",
    "documents = docs_1 + docs_2\n",
    "labels = labels_1 + labels_2\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy':  \n",
    "        for metric, value in metrics.items():\n",
    "            if isinstance(value, float):\n",
    "                metrics[metric] = round(value, 3)\n",
    "\n",
    "\n",
    "print(\"Classification Report (Rounded to 3 decimal places):\")\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy':\n",
    "        print(f\"\\nLabel: {label}\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value}\")\n",
    "\n",
    "\n",
    "new_document = [\"Python is great for data science\"] \n",
    "X_new = vectorizer.transform(new_document)\n",
    "new_pred = rf_classifier.predict(X_new)\n",
    "print(\"Predicted Category for the new document:\", label_encoder.inverse_transform(new_pred)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bca13b1-0df1-4fe1-84c4-7bd902899c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
